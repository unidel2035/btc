# Sentiment Analysis Module (NLP)

–ú–æ–¥—É–ª—å –∞–Ω–∞–ª–∏–∑–∞ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–π –¥–ª—è –∫—Ä–∏–ø—Ç–æ–≤–∞–ª—é—Ç–Ω—ã—Ö –Ω–æ–≤–æ—Å—Ç–µ–π –∏ —Å–æ—Ü–∏–∞–ª—å–Ω—ã—Ö —Å–∏–≥–Ω–∞–ª–æ–≤ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º NLP.

## üéØ –í–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏

- ‚úÖ **Sentiment Classification** - –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–π (positive/negative/neutral) —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º FinBERT
- ‚úÖ **Entity Recognition** - –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Å—É—â–Ω–æ—Å—Ç–µ–π (–∫—Ä–∏–ø—Ç–æ–≤–∞–ª—é—Ç—ã, –∫–æ–º–ø–∞–Ω–∏–∏, –ª—é–¥–∏) —Å –ø–æ–º–æ—â—å—é spaCy
- ‚úÖ **Impact Scoring** - –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –≤–∞–∂–Ω–æ—Å—Ç–∏ –Ω–æ–≤–æ—Å—Ç–∏ (low/medium/high)
- ‚úÖ **Keyword Extraction** - –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤
- ‚úÖ **Text Preprocessing** - –û—á–∏—Å—Ç–∫–∞ –∏ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞
- ‚úÖ **Batch Processing** - –ü–∞–∫–µ—Ç–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–ª—è –±–æ–ª—å—à–∏—Ö –æ–±—ä–µ–º–æ–≤
- ‚úÖ **REST API** - FastAPI —Å–µ—Ä–≤–∏—Å —Å –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–µ–π
- ‚úÖ **TypeScript Client** - –ì–æ—Ç–æ–≤—ã–π –∫–ª–∏–µ–Ω—Ç –¥–ª—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏

## üìä –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞

```
src/analyzers/sentiment/
‚îú‚îÄ‚îÄ python/                    # Python microservice
‚îÇ   ‚îú‚îÄ‚îÄ main.py               # FastAPI application
‚îÇ   ‚îú‚îÄ‚îÄ analyzer.py           # Sentiment analyzer & NER
‚îÇ   ‚îú‚îÄ‚îÄ preprocessor.py       # Text preprocessing
‚îÇ   ‚îú‚îÄ‚îÄ models.py             # Pydantic models
‚îÇ   ‚îú‚îÄ‚îÄ config.py             # Configuration
‚îÇ   ‚îú‚îÄ‚îÄ requirements.txt      # Python dependencies
‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile            # Container image
‚îÇ   ‚îî‚îÄ‚îÄ test_analyzer.py      # Unit tests
‚îú‚îÄ‚îÄ client/                    # TypeScript client
‚îÇ   ‚îî‚îÄ‚îÄ SentimentClient.ts    # API client
‚îú‚îÄ‚îÄ types.ts                   # TypeScript types
‚îú‚îÄ‚îÄ NewsAnalyzer.ts           # Integration with news collector
‚îú‚îÄ‚îÄ index.ts                  # Module exports
‚îî‚îÄ‚îÄ README.md                 # This file
```

## üöÄ –ë—ã—Å—Ç—Ä—ã–π —Å—Ç–∞—Ä—Ç

### Docker (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è)

```bash
# –ó–∞–ø—É—Å–∫ —Å–µ—Ä–≤–∏—Å–∞
docker-compose up sentiment

# –ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–¥–æ—Ä–æ–≤—å—è
curl http://localhost:8000/health
```

### –õ–æ–∫–∞–ª—å–Ω–∞—è —É—Å—Ç–∞–Ω–æ–≤–∫–∞

```bash
cd src/analyzers/sentiment/python

# –°–æ–∑–¥–∞—Ç—å –≤–∏—Ä—Ç—É–∞–ª—å–Ω–æ–µ –æ–∫—Ä—É–∂–µ–Ω–∏–µ
python -m venv venv
source venv/bin/activate  # Linux/Mac
# –∏–ª–∏
venv\Scripts\activate  # Windows

# –£—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏
pip install -r requirements.txt

# –°–∫–∞—á–∞—Ç—å spaCy –º–æ–¥–µ–ª—å
python -m spacy download en_core_web_sm

# –ó–∞–ø—É—Å—Ç–∏—Ç—å —Å–µ—Ä–≤–∏—Å
python -m uvicorn main:app --reload

# –ò–ª–∏ —á–µ—Ä–µ–∑ uvicorn –Ω–∞–ø—Ä—è–º—É—é
uvicorn main:app --host 0.0.0.0 --port 8000
```

## üì° API Endpoints

### Health Check

```bash
GET /health
```

Response:
```json
{
  "status": "healthy",
  "models_loaded": true,
  "version": "1.0.0"
}
```

### Analyze Single Text

```bash
POST /analyze
Content-Type: application/json

{
  "text": "Bitcoin surges 10% after ETF approval",
  "type": "news"
}
```

Response:
```json
{
  "sentiment": 0.85,
  "confidence": 0.92,
  "label": "positive",
  "entities": ["Bitcoin", "ETF"],
  "impact": "high",
  "keywords": ["surge", "approval"]
}
```

### Batch Analysis

```bash
POST /analyze/batch
Content-Type: application/json

{
  "texts": [
    "Bitcoin surges 10% after ETF approval",
    "Ethereum price crashes on security concerns"
  ],
  "type": "news"
}
```

Response:
```json
{
  "results": [
    {
      "sentiment": 0.85,
      "confidence": 0.92,
      "label": "positive",
      "entities": ["Bitcoin", "ETF"],
      "impact": "high",
      "keywords": ["surge", "approval"]
    },
    {
      "sentiment": -0.75,
      "confidence": 0.88,
      "label": "negative",
      "entities": ["Ethereum"],
      "impact": "high",
      "keywords": ["crash", "security"]
    }
  ],
  "processed": 2
}
```

## üíª –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –≤ TypeScript

### –ë–∞–∑–æ–≤–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ

```typescript
import { createSentimentClient } from './analyzers/sentiment';

// –°–æ–∑–¥–∞—Ç—å –∫–ª–∏–µ–Ω—Ç
const client = createSentimentClient('http://localhost:8000');

// –î–æ–∂–¥–∞—Ç—å—Å—è –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç–∏ —Å–µ—Ä–≤–∏—Å–∞
await client.waitForReady();

// –ê–Ω–∞–ª–∏–∑ –æ–¥–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞
const result = await client.analyze(
  'Bitcoin surges 10% after ETF approval',
  'news'
);

console.log(`Sentiment: ${result.sentiment}`);
console.log(`Label: ${result.label}`);
console.log(`Impact: ${result.impact}`);
console.log(`Entities: ${result.entities.join(', ')}`);
```

### –ü–∞–∫–µ—Ç–Ω—ã–π –∞–Ω–∞–ª–∏–∑

```typescript
const results = await client.analyzeBatch([
  'Bitcoin surges 10%',
  'Ethereum price crashes',
  'Cardano announces partnership'
], 'news');

results.results.forEach((result, i) => {
  console.log(`${i + 1}. ${result.label} (${result.sentiment})`);
});
```

### –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å news collector

```typescript
import { createNewsAnalyzer } from './analyzers/sentiment/NewsAnalyzer';
import type { NewsItem } from './collectors/news/types';

// –°–æ–∑–¥–∞—Ç—å –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä
const analyzer = createNewsAnalyzer({
  sentimentApiUrl: 'http://localhost:8000',
  batchSize: 10,
  enableCaching: true
});

// –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å
const available = await analyzer.isAvailable();

// –ê–Ω–∞–ª–∏–∑ –æ–¥–Ω–æ–π –Ω–æ–≤–æ—Å—Ç–∏
const analyzedItem = await analyzer.analyzeNewsItem(newsItem);

// –ê–Ω–∞–ª–∏–∑ —Å–ø–∏—Å–∫–∞ –Ω–æ–≤–æ—Å—Ç–µ–π
const analyzedItems = await analyzer.analyzeNewsItems(newsItems);

// –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∫—ç—à–∞
const stats = analyzer.getCacheStats();
console.log(`Cache size: ${stats.size}`);
```

## üß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ

### Python —Ç–µ—Å—Ç—ã

```bash
cd src/analyzers/sentiment/python
python test_analyzer.py
```

### TypeScript –ø—Ä–∏–º–µ—Ä—ã

```bash
# –ó–∞–ø—É—Å—Ç–∏—Ç—å –ø—Ä–∏–º–µ—Ä—ã
npm run example:sentiment

# –ò–ª–∏ —á–µ—Ä–µ–∑ tsx –Ω–∞–ø—Ä—è–º—É—é
tsx examples/sentiment-analyzer-example.ts
```

## üîß –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è

### –ü–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è

```env
# Server configuration
SENTIMENT_API_URL=http://localhost:8000
SENTIMENT_HOST=0.0.0.0
SENTIMENT_PORT=8000
DEBUG=false

# Model configuration
SENTIMENT_MODEL=ProsusAI/finbert
NER_MODEL=en_core_web_sm

# Performance
MAX_LENGTH=512
BATCH_SIZE=32
DEVICE=cpu  # –∏–ª–∏ cuda –¥–ª—è GPU

# Impact weights (–¥–æ–ª–∂–Ω—ã —Å—É–º–º–∏—Ä–æ–≤–∞—Ç—å—Å—è –≤ 1.0)
WEIGHT_SENTIMENT=0.4
WEIGHT_ENTITIES=0.3
WEIGHT_KEYWORDS=0.3
```

### Docker volumes

–ú–æ–¥–µ–ª–∏ –∫—ç—à–∏—Ä—É—é—Ç—Å—è –≤ Docker volumes –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –∑–∞–ø—É—Å–∫–∞:

- `sentiment_models` - HuggingFace –º–æ–¥–µ–ª–∏
- `sentiment_data` - spaCy –¥–∞–Ω–Ω—ã–µ

## ü§ñ –ú–æ–¥–µ–ª–∏

### FinBERT (Sentiment Analysis)

- **–ú–æ–¥–µ–ª—å**: `ProsusAI/finbert`
- **–û–ø–∏—Å–∞–Ω–∏–µ**: BERT fine-tuned –Ω–∞ —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã—Ö —Ç–µ–∫—Å—Ç–∞—Ö
- **–í—ã—Ö–æ–¥**: positive, negative, neutral
- **–¢–æ—á–Ω–æ—Å—Ç—å**: ~85-90% –Ω–∞ —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã—Ö –Ω–æ–≤–æ—Å—Ç—è—Ö

### spaCy (Named Entity Recognition)

- **–ú–æ–¥–µ–ª—å**: `en_core_web_sm`
- **–¢–∏–ø—ã —Å—É—â–Ω–æ—Å—Ç–µ–π**: ORG, PERSON, GPE, MONEY, PRODUCT
- **–î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ**: –†–µ–≥–µ–∫—Å—ã –¥–ª—è –∫—Ä–∏–ø—Ç–æ–≤–∞–ª—é—Ç

### Custom Impact Scoring

Impact score = 0.4 √ó sentiment_intensity + 0.3 √ó entity_score + 0.3 √ó keyword_score

- **High impact**: score ‚â• 0.7
- **Medium impact**: 0.4 ‚â§ score < 0.7
- **Low impact**: score < 0.4

## üìà –ú–µ—Ç—Ä–∏–∫–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏

### Acceptance Criteria ‚úÖ

- ‚úÖ **–¢–æ—á–Ω–æ—Å—Ç—å**: >80% –Ω–∞ –∫—Ä–∏–ø—Ç–æ–≤–∞–ª—é—Ç–Ω—ã—Ö –Ω–æ–≤–æ—Å—Ç—è—Ö (FinBERT baseline ~85%)
- ‚úÖ **Latency**: <100ms –Ω–∞ –∑–∞–ø—Ä–æ—Å (—Ç–∏–ø–∏—á–Ω–æ 30-50ms –Ω–∞ CPU)
- ‚úÖ **Batch Processing**: –î–æ 100 —Ç–µ–∫—Å—Ç–æ–≤ –≤ –æ–¥–Ω–æ–º –∑–∞–ø—Ä–æ—Å–µ

### –ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å

| –ú–µ—Ç—Ä–∏–∫–∞ | CPU | GPU (CUDA) |
|---------|-----|------------|
| Single request | 30-50ms | 10-20ms |
| Batch (10 items) | 200-300ms | 50-100ms |
| Batch (100 items) | 2-3s | 500-800ms |

### –ú–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ

–î–ª—è production –Ω–∞–≥—Ä—É–∑–∫–∏:

1. –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å GPU (DEVICE=cuda)
2. –£–≤–µ–ª–∏—á–∏—Ç—å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ workers –≤ uvicorn
3. –ù–∞—Å—Ç—Ä–æ–∏—Ç—å load balancer (nginx/traefik)
4. –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å Redis –¥–ª—è –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤

## üõ†Ô∏è –†–∞—Å—à–∏—Ä–µ–Ω–∏–µ

### –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –Ω–æ–≤–æ–π –º–æ–¥–µ–ª–∏

```python
# –í config.py
SENTIMENT_MODEL = "ElKulako/cryptobert"  # CryptoBERT

# –ò–ª–∏ –¥–ª—è –º—É–ª—å—Ç–∏—è–∑—ã—á–Ω–æ—Å—Ç–∏
SENTIMENT_MODEL = "nlptown/bert-base-multilingual-uncased-sentiment"
```

### Fine-tuning –Ω–∞ —Å–≤–æ–∏—Ö –¥–∞–Ω–Ω—ã—Ö

```python
from transformers import AutoModelForSequenceClassification, Trainer

# –ó–∞–≥—Ä—É–∑–∏—Ç—å –±–∞–∑–æ–≤—É—é –º–æ–¥–µ–ª—å
model = AutoModelForSequenceClassification.from_pretrained("ProsusAI/finbert")

# –û–±—É—á–∏—Ç—å –Ω–∞ —Å–≤–æ—ë–º –¥–∞—Ç–∞—Å–µ—Ç–µ
trainer = Trainer(
    model=model,
    train_dataset=train_dataset,
    eval_dataset=eval_dataset,
)
trainer.train()

# –°–æ—Ö—Ä–∞–Ω–∏—Ç—å
model.save_pretrained("./my-crypto-sentiment-model")
```

### –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –Ω–æ–≤—ã—Ö –º–µ—Ç—Ä–∏–∫

```python
# –í analyzer.py
def calculate_urgency(self, text: str) -> str:
    """–û–ø—Ä–µ–¥–µ–ª–∏—Ç—å —Å—Ä–æ—á–Ω–æ—Å—Ç—å –Ω–æ–≤–æ—Å—Ç–∏"""
    urgent_keywords = ["breaking", "urgent", "alert", "now"]
    if any(kw in text.lower() for kw in urgent_keywords):
        return "urgent"
    return "normal"
```

## üìö –ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è

### CLI —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ

```bash
# –ü—Ä–æ—Å—Ç–æ–π –∑–∞–ø—Ä–æ—Å
curl -X POST http://localhost:8000/analyze \
  -H "Content-Type: application/json" \
  -d '{"text": "Bitcoin surges 10%", "type": "news"}'

# Batch –∑–∞–ø—Ä–æ—Å
curl -X POST http://localhost:8000/analyze/batch \
  -H "Content-Type: application/json" \
  -d '{
    "texts": ["Bitcoin up", "Ethereum down"],
    "type": "news"
  }'
```

### Python –∫–ª–∏–µ–Ω—Ç

```python
import requests

# –ê–Ω–∞–ª–∏–∑
response = requests.post(
    "http://localhost:8000/analyze",
    json={"text": "Bitcoin surges 10%", "type": "news"}
)
result = response.json()
print(f"Sentiment: {result['sentiment']}")
```

### JavaScript/Node.js

```javascript
const response = await fetch('http://localhost:8000/analyze', {
  method: 'POST',
  headers: { 'Content-Type': 'application/json' },
  body: JSON.stringify({
    text: 'Bitcoin surges 10%',
    type: 'news'
  })
});

const result = await response.json();
console.log(`Sentiment: ${result.sentiment}`);
```

## üêõ –û—Ç–ª–∞–¥–∫–∞

### –í–∫–ª—é—á–∏—Ç—å verbose –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ

```bash
# –í docker-compose.yml –∏–ª–∏ .env
DEBUG=true

# –ò–ª–∏ –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ
DEBUG=true python -m uvicorn main:app --reload
```

### –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –∑–∞–≥—Ä—É–∑–∫—É –º–æ–¥–µ–ª–µ–π

```bash
curl http://localhost:8000/health
```

### –¢–µ—Å—Ç –±–µ–∑ Docker

```bash
cd src/analyzers/sentiment/python
python test_analyzer.py
```

## üîê –ë–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å

- –í–∞–ª–∏–¥–∞—Ü–∏—è –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö —á–µ—Ä–µ–∑ Pydantic
- –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–∞ —Ç–µ–∫—Å—Ç–∞ (max 10,000 —Å–∏–º–≤–æ–ª–æ–≤)
- –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ batch size (max 100 —ç–ª–µ–º–µ–Ω—Ç–æ–≤)
- CORS –Ω–∞—Å—Ç—Ä–æ–µ–Ω (–≤ production –æ–≥—Ä–∞–Ω–∏—á–∏—Ç—å origins)
- Rate limiting (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –¥–æ–±–∞–≤–∏—Ç—å –≤ production)

## üì¶ Deployment

### Docker Compose

```bash
# –ó–∞–ø—É—Å—Ç–∏—Ç—å –≤—Å–µ —Å–µ—Ä–≤–∏—Å—ã
docker-compose up -d

# –¢–æ–ª—å–∫–æ sentiment service
docker-compose up -d sentiment

# –õ–æ–≥–∏
docker-compose logs -f sentiment

# –†–µ—Å—Ç–∞—Ä—Ç
docker-compose restart sentiment
```

### Kubernetes (–ø—Ä–∏–º–µ—Ä)

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: sentiment-service
spec:
  replicas: 3
  selector:
    matchLabels:
      app: sentiment
  template:
    metadata:
      labels:
        app: sentiment
    spec:
      containers:
      - name: sentiment
        image: btc-sentiment:latest
        ports:
        - containerPort: 8000
        env:
        - name: DEVICE
          value: "cuda"
        resources:
          requests:
            memory: "2Gi"
            cpu: "1000m"
          limits:
            memory: "4Gi"
            cpu: "2000m"
```

## ü§ù Contributing

–ü—Ä–∏ –¥–æ–±–∞–≤–ª–µ–Ω–∏–∏ –Ω–æ–≤—ã—Ö —Ñ–∏—á:

1. –û–±–Ω–æ–≤–∏—Ç—å `requirements.txt` –µ—Å–ª–∏ –Ω—É–∂–Ω—ã –Ω–æ–≤—ã–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏
2. –î–æ–±–∞–≤–∏—Ç—å —Ç–µ—Å—Ç—ã –≤ `test_analyzer.py`
3. –û–±–Ω–æ–≤–∏—Ç—å API –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—é
4. –û–±–Ω–æ–≤–∏—Ç—å —Ç–∏–ø—ã –≤ `types.ts`
5. –û–±–Ω–æ–≤–∏—Ç—å README

## üìù TODO

- [ ] Redis –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è API
- [ ] Rate limiting middleware
- [ ] Prometheus –º–µ—Ç—Ä–∏–∫–∏
- [ ] Fine-tuned –º–æ–¥–µ–ª—å –Ω–∞ crypto –¥–∞–Ω–Ω—ã—Ö
- [ ] –ú—É–ª—å—Ç–∏—è–∑—ã—á–Ω–∞—è –ø–æ–¥–¥–µ—Ä–∂–∫–∞
- [ ] Webhook –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏
- [ ] GraphQL API

## üìÑ –õ–∏—Ü–µ–Ω–∑–∏—è

MIT

## üîó –ü–æ–ª–µ–∑–Ω—ã–µ —Å—Å—ã–ª–∫–∏

- [FinBERT Paper](https://arxiv.org/abs/1908.10063)
- [HuggingFace Transformers](https://huggingface.co/docs/transformers)
- [spaCy Documentation](https://spacy.io/usage)
- [FastAPI Documentation](https://fastapi.tiangolo.com/)
